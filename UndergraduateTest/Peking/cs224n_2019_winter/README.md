CS224n:Nature Language Processing with Deep Learning
====================================================

winter 2019
-------------

- 往届视频（winter 2017）：https://www.bilibili.com/video/av13383754

## 课表进度跟进ing

### 1.08 Introduction and Word Vectors

- slides: ![pdf](./1.08/cs224n-2019-lecture01-wordvecs1.pdf)
- suggested readings:
    1. ![Word2Vec Tutorial - The Skip-Gram Model](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/)
    2. ![Efficient Estimation of Word Representations in Vector Space (original word2vec paper)](http://arxiv.org/pdf/1301.3781.pdf)
    3. ![Distributed Representations of Words and Phrases and their Compositionality (negative sampling paper)](http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)
    
- Assignment 1

    ![preview](http://web.stanford.edu/class/cs224n/assignments/a1_preview/exploring_word_vectors.html)

###1.10 Word Vectors 2 and Word Senses

- slides: ![pdf](./1.08/cs224n-2019-lecture01-wordvecs1.pdf)
- suggested readings:
    1. ![Word2Vec Tutorial - The Skip-Gram Model](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/)
    2. ![Efficient Estimation of Word Representations in Vector Space (original word2vec paper)](http://arxiv.org/pdf/1301.3781.pdf)
    3. ![Distributed Representations of Words and Phrases and their Compositionality (negative sampling paper)](http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)
  


- 补充资料（入门首选）



下面这些学习资料都可以在线免费阅读！这些书籍、PPT 都可以在大家学习过程中起到作用：



https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1184/syllabus.html

https://web.stanford.edu/~jurafsky/slp3/

https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf

http://u.cs.biu.ac.il/~yogo/nnlp.pdf

http://www.deeplearningbook.org/



如果没有神经网络或者深度学习基础或者背景，可以先从下面这两本书入门：



http://neuralnetworksanddeeplearning.com/

https://mitpress.mit.edu/books/introduction-deep-learning

- 往届资料

2018 年冬季课程、报告:

https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1184/

https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1184/reports.html



2017 年冬季课程、报告：

https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1174/

https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1174/reports.html



更早之前的课程：

http://cs224d.stanford.edu/reports_2016.html

https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1162/

https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1184/



（原文）2019 年最新课程全介绍：

http://web.stanford.edu/class/cs224n/